---
title: '"Dynamic Analysis of Bike Station Utilization Over Time"'
author:
  - name: YiChen Chen
date: '`r Sys.Date()`'
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
	echo = TRUE,
	message = FALSE,
	error = FALSE,
	warning = FALSE
)
options(digits=22)
```

In our previous class demonstrations and homeworks, we practiced exploring Citi Bike ride data to gain insights into the bike share's rebalancing efforts. In the process, we gained experience transforming data and mapping data to visual encodings. First, as a class we practiced using a workflow with Citi Bike data to create a new variable, an indicator whether bikes may have been rebalanced. Next, in homework two, we practiced mapping Citi Bike ride data onto the three attributes of color: hue, saturation, and luminance. In the process we were able to explore how useage, rebalancing efforts, or both may have changed between 2013 and 2019, and again before and after the pandemic began. This exploration also helped us consider some of the limitations of the particular visualization: it did not consider the effects of rebalancing or bike and docking station availability. In this assignment, we will try to account for those and other limitations in the visualizations, and in the process gain practice with new data graphics and *explaining* our insights to others.


# Preliminary setup

Load libraries to access functions we'll use in this analysis.

```{r}
library(tidyverse) # the usual
library(sf)        # for map data
library(patchwork) # for organizing multiple graphs
library(ggthemes)  # collection of graph themes
theme_set(theme_tufte(base_family = 'sans')) 
```

The dataset

```{r}
rider_trips <- read_csv('data/201909-citibike-tripdata.csv')
rider_trips <- 
  rider_trips %>% 
  rename_all(function(x) gsub(' ', '_', x)) %>%
  rename(start_time = starttime,
         end_time = stoptime) %>%
  mutate(tripduration = as.difftime(tripduration / 3600, units = 'hours') )
```

Previously, we considered that, in general, Citi Bike's available data include measures of several attributes for each bike ride. When a bikeshare customer begins their ride, Citi Bike measures these attributes,

```         
bikeid
start_station_id
start_station_name
start_station_longitude
start_station_latitude
start_time
```

For the same record (row in the data), when a bikeshare customer ends their ride, Citi Bike measures additional attributes:

```         
end_station_id
end_station_name
end_station_longitude
end_station_latitude
end_time
```

We'll also use the variable `usertype`, and the calculated variable `tripduration`. Of note, while Citi Bike also records other attributes about the ride (*e.g.*, `birthyear`, `gender`), we'll ignore these here.

Thus, for customer rides, any given ride begins at the same station that the previous ride ended. Described with math, for rides $n \in 1, 2, ... N$ of each bike $b \in 1, 2, ... B$, we can express bike location between rides as

$$
\textrm{end_station_name}_{b, n} = \textrm{start_station_name}_{b, n+1}  \mid \textrm{normal usage}
$$

This does not always hold, however, when Citi Bike intervenes between rides by removing a bike from a docking station for whatever reason (*e.g.*, rebalancing or repair); Citi Bike may redock the bike anywhere or not at all. By combining information for ride $n$ and $n+1$, we can create *intervention* observations and by filtering to only keep transitions where

$$
\textrm{end_station_name}_{b, n} \ne \textrm{start_station_name}_{b, n+1}  \mid \textrm{intervention}
$$

# measuring CitiBike interventions (data transformations)


Create observations for Citi Bike's "interventions". This process is designed to track and analyze the intervals between bike rides, identifying any instances where bikes are moved or remain stationary between trips. By organizing and filtering the data in this way, we can better understand the operational dynamics of the bike-sharing system, such as bike rebalancing and usage patterns.

```         
bikeid
start_station_id
start_station_name
start_station_longitude
start_station_latitude
start_time
end_station_id
end_station_name
end_station_longitude
end_station_latitude
end_time
usertype
tripduration
```

Name the new dataframe as the object `interventions`.

```{r}

# ENTER CODE TO TRANSFORM DATA INTO interventions
interventions <- rider_trips %>%
  select( -birth_year, -gender ) %>%
  arrange(
    bikeid, start_time
  ) %>%
  group_by(
    bikeid
  ) %>%
   mutate(
    across(
      .cols = matches('end_'),
      .fns = lag
    )
  ) %>%
  rename_with(
    .cols = contains('time') | contains('_station_'),
    ~ if_else(
        str_detect(., 'start'),
        str_replace(., 'start', 'end'),
        str_replace(., 'end', 'start')
      )
  ) %>%
  filter(
    start_station_id != end_station_id,
    !is.na(start_station_id)
  ) %>%
  ungroup() %>%
  mutate(
    usertype = 'Citi Bike',
    tripduration = as.numeric(difftime(end_time, start_time, units = 'hours'))
  )
interventions 
```


We're curious about a docking station near Madison Square Garden: the station name is 'W 31 St & 7 Ave' and its station id is 379. How many trips originated from this station, and what percent of stations had more rides leaving?

```{r}
# total trip originated from id 379
total_trip_379 <- rider_trips %>%
  filter(start_station_id == 379) %>%
  nrow()

# number of trips originating from each station
trips_per_station <- rider_trips %>%
  group_by(start_station_id) %>%
  summarise(total_trips = n())


# number of station has more trips leavng than station 379
station_with_more_ride <- trips_per_station %>% 
  filter(total_trips > total_trip_379 ) %>%
  nrow()

# percent of stations had more rides leaving

(station_with_more_ride/ nrow(trips_per_station)) *100



```

> Trips originated from 'W 31 St & 7 Ave' (Station ID 379): 9481
>
> Percentage of stations with more rides leaving: 3.726708 %


For the same station, how many bikes did Citi Bike remove due to interventions, and what percent of stations did Citi Bike remove more bikes?

```{r}
# number of Citi Bike remove due to interventions from id 379
total_remove_379 <-  interventions %>% 
  filter(start_station_id == 379) %>%
  nrow()
total_remove_379

# number of Citi Bike remove due to interventions from each station
remove_per_station <- interventions %>%
  group_by(start_station_id) %>%
  summarise(total_interventions = n())
remove_per_station

# number of stations remove more bikes than 379
station_with_more_remove <- remove_per_station %>% 
  filter(total_interventions > total_remove_379 ) %>%
  nrow()
station_with_more_remove

# what is the percentage
100 * (station_with_more_remove / nrow(remove_per_station))


```

> Bikes remove due to interventions from 'W 31 St & 7 Ave' (Station ID 379): 48
>
> Percentage of stations with more interventions: 23 %

## 

Using ggplot2 and the principles of the grammar of graphics, create a histogram to visualize how frequently bikes are removed from stations. Set the histogram's bin width to 100 to group the data effectively. Be sure to label the x-axis and y-axis clearly, and provide a meaningful title that conveys your insights, not just data. Follow visual communication best practices to ensure the histogram is both informative and engaging.

```{r}

#number of interventions removing bikes across stations.
remove_per_station

# histogram
ggplot(remove_per_station, aes(x = total_interventions)) +
  geom_histogram(binwidth = 100, fill = "lightpink", color = "coral2") +
  labs(
    x = "Number of Interventions Removing Bikes",
    y = "Number of Stations",
    title = "Distribution of Interventions Removing Bikes Across Stations"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", color = "coral3"), 
    axis.text = element_text(size = 10, color = "darkred"), 
    axis.title = element_text(size = 12, color = "darkred") )
```

# visualizing time between rides (visually encoding data)

Applying the grammar of graphics with `ggplot2`, 1) create a histogram of your calculated `tripduration` in the new data frame `interventions`, 2) layer a red, vertical line onto the histogram that marks `24` hours, and 3) add *explanatory* information including `x` and `y` labels, the main takeaway or interpretation (message, not just information) as a `title`, and a `caption` describing the source of your data.

```{r}
library(ggplot2)

ggplot(interventions, aes(x = tripduration)) +
  geom_histogram(binwidth = 1, fill = "lightpink", color = "coral") +
  labs(
    x = "Trip Duration (hours)",
    y = "Frequency",
    title = "Distribution of Trip Durations for Citi Bike Interventions",
    caption = "Data source: Citi Bike interventions dataset"
  ) +
  scale_x_continuous(limits = c(0, 100)) +
   scale_y_continuous(limits = c(0, 4500)) +
   geom_vline(xintercept = 24, color = "red", linetype = "dashed", size = 0.8) +
  geom_text(x = 32, y = 1000, label = "24 hours", color = "red", angle = 0, vjust = -1) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", color = "coral3"),
    axis.text = element_text(size = 10,  color = "darkred"),
    axis.title = element_text(size = 12,  color = "darkred"),
    plot.caption = element_text(size = 8, color = "grey")
  )


```



# visualize location of interventions (visually encoding data)


We might think of these interventions geographically (that is, locations in space). First, to visualize these interventions as locations in space, we'll overlay visual encodings onto a map of Manhattan. We can create the base map from geographic data available at [Beta NYC](https://beta.nyc/products/boundaries-map/), which we convert from the available data structure called a *spatial polygon data frame*, into a regular data frame of which we are familiar. Here's the code:

```{r}
# location of spatial polygon data frame to tibble (data.frame) for
# boroughs and neighborhoods, convert to sf data frame

url <- str_c(
    'https://ssp3nc3r.github.io/',
    '20213APAN5800K007/data/betanyc_hoods.geojson'
    )

nyc_neighborhoods <- read_sf(url)
```

Inspect the simple features data frame, `nyc_neighborhoods`, notice that the variable geometry contains a storage type called POLYGON, which contains information that describes the geographic locations we're interested in.

From these data frames, we draw a base map of Manhattan that also shows its neighborhood boundaries. Review the help file for `geom_sf`, the function we'll use to map this spatial data onto visual encodings. Again, here's some code to create our base map:

```{r}
p_hoods <- 
  
  # initialize graph
  ggplot() + 
  
  # remove most non-data ink
  theme_void() +
  
  # add color for water (behind land polygons)
  theme(
    panel.background = element_rect(fill = 'lightblue')
  ) +
  
  # map boundary data to visual elements (polygons)
  geom_sf(
    data = nyc_neighborhoods,
    mapping = aes(geometry = geometry),
    fill = 'white',
    color = 'gray',
    lwd = 0.1
  ) +
  
  # define coordinate system and zoom in on Manhattan
  coord_sf(
    crs = sf::st_crs(4326), # World Geodetic System 1984 (WGS84)
    xlim = c(-74.03, -73.91),
    ylim = c( 40.695, 40.85)
  )


# display the graph
p_hoods


library(viridis)
library(dplyr)

# Assuming interventions data frame contains intervention data

# Calculate the number of interventions for each station
interventions_count <- interventions %>%
  group_by(end_station_id) %>%
  summarise(intervention_count = n())
interventions_count

# Merge intervention count with station location data
interventions_with_count <- left_join(interventions, interventions_count, by = "end_station_id")

# Plot map with bigger points for stations with more interventions
mybreaks <- c(500, 1000, 1500)
  
p_hoods +
  geom_point(data = interventions_with_count,
             aes(x = end_station_longitude,
                 y = end_station_latitude,
                 size = intervention_count,
                 color = intervention_count),
             shape = 20, stroke = FALSE, alpha = 1) +
    scale_size_continuous(name = "Intervention Count", range = c(0.8, 3), 
                        trans = "log", breaks = mybreaks) +
  scale_alpha_continuous(name = "Intervention Count", range = c(0.09, 0.5), 
                         trans = "log", breaks = mybreaks) +
  scale_color_viridis(option = "magma", name = "Intervention Count", trans = "log", breaks = mybreaks) +
  guides(color = guide_legend()) +
  ggtitle("Interventions in Manhattan")



```

```{r}
interventions <- interventions %>%
  mutate(tripduration = as.difftime(tripduration, units = "hours"))

allmoves <- bind_rows(rider_trips, interventions)

```

# Qestimating number of bikes at stations (data transformation and visual encodings)

To track bike availability at each station over time, analyze the changes using our data sets. Each bike that arrives at a station is counted as an addition, and each departure as a subtraction. Sum these changes cumulatively to model the number of bikes available at any time. Since the data starts at the beginning of a month and bikes were already at the stations, adjust the initial counts to reflect this. This method gives us an ongoing tally of bike availability, and it's applied to both the overall activity and specific interventions separately.

```{r}
allmoves_observed_rides <- allmoves %>% # Select and rename relevant columns
  select(start_station_id, end_station_id, start_time, end_time) %>%
  mutate(start_ride = -1, end_ride = 1) %>%    # Reshape data
  pivot_longer(cols = c(start_ride, end_ride), names_to = "ride_type", values_to = "bike_count") %>% 
# Determine the time and station_id based on ride_type, ensuring time retains POSIXct format
   mutate(
    time = case_when(  ride_type == "start_ride" ~ start_time, TRUE ~ end_time ),
    station_id = case_when( ride_type == "start_ride" ~ start_station_id, TRUE ~ end_station_id))  %>%
  select(-start_time, -end_time, -start_station_id, -end_station_id, -ride_type) %>%
  # Drop unnecessary columns
   arrange(time) %>%  # Order by time
   group_by(station_id) %>%  
  # calculate cumulative sum and adjustments
 mutate(
    cumulative_bikes = cumsum(bike_count),
    adjusted_bikes = cumulative_bikes - min(cumulative_bikes)
  ) %>%
  ungroup()




interventions_observed_rides <- interventions %>%
  select(start_station_id, end_station_id, start_time, end_time) %>%
  mutate(start_ride = -1, end_ride = 1) %>%
  pivot_longer(cols = c(start_ride, end_ride), names_to = "ride_type", values_to = "bike_count") %>%
  mutate(
    time = case_when(ride_type == "start_ride" ~ start_time, TRUE ~ end_time),
    station_id = case_when(ride_type == "start_ride" ~ start_station_id, TRUE ~ end_station_id)
  ) %>%
  select(-start_time, -end_time, -start_station_id, -end_station_id, -ride_type) %>%
  arrange(time) %>%
  group_by(station_id) %>%
  mutate(
    cumulative_bikes = cumsum(bike_count)
  ) %>%
  ungroup() %>%
  group_by(station_id) %>%
  mutate(
    adjusted_bikes = cumulative_bikes - min(cumulative_bikes)
  ) %>%
  ungroup()

  
 
```

In the step of visually encoding the transformed data, graph the two cumulative sums of all across time at one particular station: "W 31 St & 7 Ave", which is near Penn Station. Categorically encode the cumulative sum of combined trips and interventions in *black*, and encode the cumulative sum of just interventions in *red*.

```{r}
# filter particular station
allmoves_379_station <- allmoves_observed_rides %>%
  filter(station_id == "379")
interventions_379_station <- interventions_observed_rides %>%
  filter(station_id == "379")

#combined trip
combined_data <- bind_rows( 
  allmoves_379_station %>% 
    mutate(category = "Trips and Interventions"),
  interventions_379_station %>%
    mutate(category = "Just Interventions"))


ggplot(combined_data, aes(x = time, y = adjusted_bikes, color = category)) +
  geom_line() +
  scale_color_manual(values = c("Trips and Interventions" = "black", "Just Interventions" = "red")) +
  labs(title = "Cumulative Bikes over Time at W 31 St & 7 Ave Station",
       x = "Time",
       y = "Adjusted Cumulative Bikes",
       color = "Category") +
  theme_minimal()




```



```{r}

ggplot(combined_data, aes(x = time, y = adjusted_bikes, color = category)) +
  geom_line() +
  scale_color_manual(values = c("Trips and Interventions" = "black", "Just Interventions" = "red")) +
  
  labs(title = "Bike Usage and Rebalancing Insights",
       subtitle = "Adjusted cumulative bike counts at W 31 St & 7 Ave Station show usage patterns and intervention efforts",
       x = "Time",
       y = "Adjusted Cumulative Bikes",
       color = "Category") +
  
  # Customizing the theme to make it more accessible
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "italic"),
        legend.position = "bottom",
        plot.margin = margin(t = 5.5, r = 40, b = 5.5, l = 5.5, unit = "pt")) +
  coord_cartesian(clip = "off") + 
   theme(plot.background = element_blank(),
        panel.background = element_blank()) +
  
  # Adding annotations for specific observations
 annotate("text", x = as.POSIXct('2019-09-07'), y = -5, label = "Unknow Variable: low intervention ", color = "blue", size = 3, angle = 360, vjust = 1) +
  annotate("text", x = as.POSIXct('2019-09-10'), y = 60, label = "Unknow Variable: high intervention ", color = "blue", size = 3, angle = 360, vjust = 1) +
  
  # Adding custom annotations to explain the markings
  geom_label(aes(x = as.POSIXct('2019-09-28'), y = 55, label = "responses to high usage or perhaps low availability "),
             color = "white", fill = "darkgrey", size = 3) +
  geom_label(aes(x = as.POSIXct('2019-09-28'), y = 110, label = "indicate upward rebalancing interventions"),
             color = "white", fill = "red", size = 3)




```

# References cited

Properly **Cite** all resources used in completing this assignment:

Center for Spatial Research. (n.d.). *CitiBike Rebalancing Study*. Columbia University. Retrieved Mar 26, 2024, from <https://c4sr.columbia.edu/projects/citibike-rebalancing-study>

Citi Bike NYC. (n.d.). *Citi Bike System Data*. Retrieved Mar 26, 2024, from <https://citibikenyc.com/system-data>



